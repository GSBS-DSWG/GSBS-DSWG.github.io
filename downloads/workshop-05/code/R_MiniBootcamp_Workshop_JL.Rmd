# R Mini Bootcamp: Beginner-level Focus

#### Jake Leighton - G&E Data Science Working Group

Adapted from MDACC DPLM Computational Training Program
Shared for educational use as part of this workshop

#### February 5th, 2026

# 1 Welcome to R Programming!

This document contains all the code and exercises for our introductory R Programming Workshop. This workshop is designed
for complete beginners with no prior programming experience.

## 1.1 Learning Objectives

By the end of this workshop, you will be able to:

**Part 1: R Fundamentals and Data Structures**

-   Navigate the RStudio interface

-   Install R packages and load libraries

-   Understand basic data types in R

-   Create and manipulate vectors

-   Work with data frames

-   Access built-in datasets

**Part 2: Data Import and Manipulation**

-   Import and export data files

-   Handle missing data appropriately

-   Manipulate data frames using base R

-   Use tidyverse/dplyr for elegant data manipulation

-   Chain operations using the pipe operator

# 2 PART 1: R Fundamentals and Data Structures

# 3 Getting Started with RStudio

## 3.1 The RStudio Interface

RStudio has four main panes:

1.  **Script Editor** (top-left): Write and save your code

2.  **Console** (bottom-left): Run commands interactively

3.  **Environment/History** (top-right): See your variables

4.  **Files/Plots/Packages/Help** (bottom-right): Navigate files and view outputs

## 3.2 Your First R Commands

```{r}
# This is a comment - R ignores anything after #
print("Hello, TMP!")
```

```{r}
# R can be used as a calculator
2 + 2
```

```{r}
10 * 5
```

```{r}
100 / 4
```

## 3.3 What are R Packages?

**Packages** = Collections of functions, data, and documentation that extend R’s capabilities

**Library** = The folder where packages are stored on your computer

Think of packages as toolboxes with specialized tools for specific tasks.

## 3.4 Installing Packages

```{r}
# Install a single package from CRAN
install.packages("ggplot2")

# Install multiple packages
install.packages(c("tidyverse", "dplyr", "tidyr", "readr", "lubridate", "patchwork"))

# Install from GitHub (requires devtools)
install.packages("devtools")
devtools::install_github("username/packagename")

# Install from Bioconductor
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("ComplexHeatmap")
```

**Note:** You only *install* once, but must *load* packages each R session.

## 3.5 Loading Packages

```{r}
# Load a package for use
library(ggplot2)

# Alternative method
require(dplyr)
```

## 3.6 Essential Package Commands

```{r}
# Check if package is installed
"ggplot2" %in% rownames(installed.packages())

# List loaded packages
(.packages())

# Update all packages
update.packages(ask = FALSE)

# Get help on a package
help(package = "ggplot2")

# Remove a package
remove.packages("packagename")
```

## 3.7 Common Issues & Solutions

| Issue                                  | Solution                                                       |
|----------------------------------------|----------------------------------------------------------------|
| "Package not found” after installation | Load it with `library()` first                                 |
| “Not available for this version of R”  | Update R or find compatible package version                    |
| Permission errors                      | Run RStudio as administrator (Windows) or set personal library |
| Package version not found in CRAN      | Install from Bioconductor or GitHub                            |

## 3.8 Getting Help

```{r}
# Get help on a function
?mean
# help(mean)  # Alternative way

# Search for help topics
# help.search("average")
```

# 4 Basic Data Types

## 4.1 Numeric, Character, and Logical

```{r}
# Numeric
my_number <- 42
my_decimal <- 3.14

# Character (text)
my_name <- "R Programmer"
my_sentence <- 'I love R!'  # Single or double quotes work

# Logical (TRUE/FALSE)
is_fun <- TRUE
is_difficult <- FALSE

# Check the type of a variable
class(my_number)
```

```{r}
class(my_name)
```

```{r}
class(is_fun)
```

## 4.2 Variables and Assignment

```{r}
# Use <- for assignment (preferred in R)
x <- 10
y <- 20

# You can also use = but <- is conventional
z = 30

# Perform operations with variables
result <- x + y + z
result
```

```{r}
# Variable names should be descriptive
student_age <- 22
student_name <- "Alice"
```

# 5 Working with Vectors

## 5.1 Creating Vectors

```{r}
# Use c() to combine elements into a vector
numbers <- c(1, 2, 3, 4, 5)
numbers
```

```{r}
# Create sequences
seq_1_to_10 <- 1:10
seq_1_to_10
```

```{r}
# More complex sequences
even_numbers <- seq(from = 2, to = 20, by = 2)
even_numbers
```

```{r}
# Repeating values
repeated <- rep(100, times = 5)
repeated
```

```{r}
# Character vectors
fruits <- c("apple", "banana", "orange", "grape")
fruits
```

```{r}
# Logical vectors
test_scores <- c(TRUE, TRUE, FALSE, TRUE)
test_scores
```

## 5.2 Vector Operations

```{r}
# Arithmetic operations apply to all elements
numbers <- c(1, 2, 3, 4, 5)
numbers * 2
```

```{r}
numbers + 10
```

```{r}
numbers^2
```

```{r}
# Operations between vectors
vec1 <- c(1, 2, 3)
vec2 <- c(10, 20, 30)
vec1 + vec2
```

```{r}
vec1 * vec2
```

```{r}
# Vector recycling (R repeats shorter vector)
long_vec <- 1:10
short_vec <- c(1, 2)
long_vec + short_vec  # short_vec is recycled
```

## 5.3 Indexing and Subsetting Vectors

```{r}
fruits <- c("apple", "banana", "orange", "grape", "kiwi")

# Access single element (R uses 1-based indexing)
fruits[1]  # First element
```

```{r}
fruits[3]  # Third element
```

```{r}
# Access multiple elements
fruits[c(1, 3, 5)]
```

```{r}
fruits[2:4]
```

```{r}
# Negative indexing (exclude elements)
fruits[-1]  # All except first
```

```{r}
fruits[-c(2, 4)]  # All except 2nd and 4th
```

```{r}
# Logical indexing
numbers <- c(10, 25, 30, 45, 50)
numbers > 30
```

```{r}
numbers[numbers > 30]  # Get elements greater than 30
```

## 5.4 Vector Functions

```{r}
numbers <- c(15, 28, 31, 42, 56, 67, 73, 89, 91, 100)

# Basic statistics
length(numbers)
```

```{r}
sum(numbers)
```

```{r}
mean(numbers)
```

```{r}
median(numbers)
```

```{r}
min(numbers)
```

```{r}
max(numbers)
```

```{r}
range(numbers)
```

```{r}
# Other useful functions
sort(numbers)
```

```{r}
rev(numbers)
```

```{r}
unique(c(1, 2, 2, 3, 3, 3, 4))
```

# 6 Data Structures

## 6.1 Lists

```{r}
# Lists can contain different types
my_list <- list(
  name = "John",
  age = 30,
  scores = c(85, 90, 78),
  passed = TRUE
)
my_list
```

```{r}
# Access list elements
my_list$name
```

```{r}
my_list[[1]]  # By position
```

```{r}
my_list[["age"]]  # By name
```

```{r}
# Lists can contain other lists
nested_list <- list(
  student1 = list(name = "Alice", grade = 85),
  student2 = list(name = "Bob", grade = 92)
)
nested_list
```

## 6.2 Matrices

```{r}
# Create a matrix
matrix1 <- matrix(1:12, nrow = 3, ncol = 4)
matrix1
```

```{r}
# Create by binding vector rows
row1 <- c(1, 2, 3)
row2 <- c(4, 5, 6)
row3 <- c(7, 8, 9)
matrix2 <- rbind(row1, row2, row3)
matrix2
```

```{r}
# Create by binding vector columns
col1 <- c(1, 2, 3)
col2 <- c(4, 5, 6)
col3 <- c(7, 8, 9)
matrix3 <- cbind(col1, col2, col3)
matrix3
```

```{r}
# Access elements
matrix3[1, 2]  # Row 1, Column 2
```

```{r}
matrix3[2, ]   # All of row 2
```

```{r}
matrix3[, 3]   # All of column 3
```

## 6.3 Data Frames - The Most Important Structure!

Data frames are the workhorse of R data analysis. They are similar to spreadsheets or tables, with rows representing
observations and columns representing variables.

```{r}
# Create a data frame from vectors
student_names <- c("Alice", "Bob", "Charlie", "Diana")
ages <- c(21, 22, 20, 23)
grades <- c(85, 92, 78, 95)
passed <- c(TRUE, TRUE, FALSE, TRUE)

students <- data.frame(
  name = student_names,
  age = ages,
  grade = grades,
  passed = passed
)
students
```

```{r}
# Alternatively use cbind and colnames
students_v2 <- as.data.frame(cbind(student_names, ages, grades, passed))
colnames(students_v2) <- c("name", "age", "grade", "passed")
students_v2
```

```{r}
# Check structure
str(students)
```

```{r}
str(students_v2)
```

## 6.4 Working with Data Frames

```{r}
# View first/last rows
head(students, 2)
```

```{r}
tail(students, 2)
```

```{r}
# Get dimensions
nrow(students)
```

```{r}
ncol(students)
```

```{r}
dim(students)
```

```{r}
# Access columns
students$name
```

```{r}
students[["grade"]]
```

```{r}
students[, "age"]
```

```{r}
students[, 2]  # Second column
```

```{r}
# Access rows
students[1, ]  # First row
```

```{r}
students[2:3, ]  # Rows 2 and 3
```

```{r}
# Access specific cells
students[1, 3]  # Row 1, Column 3
```

```{r}
students[2, "grade"]  # Row 2, grade column
```

```{r}
# Add new column
students$letter_grade <- c("B", "A", "C", "A")
students
```

```{r}
# Merging data frames
name <- c("Bob", "Alice", "Charlie")
year <- c("Senior", "Junior", "Sophomore")
students_year <- as.data.frame(cbind(name, year))
students_year
```

```{r}
students_years <- merge(students, students_year)
students_years
```

```{r}
# Summary statistics
summary(students_years)
```

# 7 Working with Built-in Datasets

```{r}
# R comes with many datasets for practice
# Let's explore options from the built-in {datasets} package
data()  # See available datasets

# Load and explore mtcars
data(mtcars)
head(mtcars)
```

```{r}
# Basic exploration
str(mtcars)
```

```{r}
summary(mtcars)
```

```{r}
colnames(mtcars)
```

```{r}
# Try another dataset
data(iris)
head(iris)
```

```{r}
dim(iris)
```

# 8 Saving Code/Workspace and Exiting Session

```{r}
# Open/Save R code as .R file
# File -> New File -> R Script
# File -> Save As -> my_code.R
# source("my_code.R")

# Save the workspace to a .RData file
# Environment -> save icon 
save.image(file = "my_workspace.RData")
# load("~/my_workspace.RData")

# Exiting RStudio Session
rm(list=ls())
dev.off()
# RStudio -> Quit RStudio
# Don't Save workspace image to .RData!!
```

# 9 Practice Exercises: Part 1

## 9.1 Exercise 1: Vector Manipulation

```{r}
# Create a vector of temperatures in Celsius
temps_c <- c(...)

# 1. Convert to Fahrenheit (F = C * 9/5 + 32)

# 2. Find temperatures above 20°C

# 3. Calculate the mean temperature

# 4. Find the hottest and coldest days
```

## 9.2 Exercise 1: Solution

```{r}
# Create a vector of temperatures in Celsius
temps_c <- c(20, 25, 18, 30, 22, 27, 15)

# 1. Convert to Fahrenheit
temps_f <- temps_c * 9/5 + 32
temps_f
```

```{r}
# 2. Find temperatures above 20°C
warm_days <- temps_c[temps_c > 20]
warm_days
```

```{r}
# 3. Calculate the mean temperature
avg_temp <- mean(temps_c)
avg_temp
```

```{r}
# 4. Find the hottest and coldest days
hottest <- max(temps_c)
coldest <- min(temps_c)
c(hottest = hottest, coldest = coldest)
```

## 9.3 Exercise 2: Create Your Own Data Frame

```{r}
# Create a data frame about books with:
# - title (at least 4 books)
# - author
# - pages
# - fiction (TRUE/FALSE)

books <- data.frame(...
)

# 1. Display the structure of your data frame

# 2. Find books with more than 300 pages

# 3. Calculate the average number of pages

# 4. Show only fiction books
```

## 9.4 Exercise 2: Solution

```{r}
# Create a data frame about books
books <- data.frame(
  title = c("1984", "Pride and Prejudice", "Sapiens", "The Hobbit"),
  author = c("Orwell", "Austen", "Harari", "Tolkien"),
  pages = c(328, 432, 443, 310),
  fiction = c(TRUE, TRUE, FALSE, TRUE)
)

# 1. Display the structure
str(books)
```

```{r}
# 2. Find books with more than 300 pages
long_books <- books[books$pages > 300, ]
long_books
```

```{r}
# 3. Calculate the average number of pages
mean(books$pages)
```

```{r}
# 4. Show only fiction books
fiction_books <- books[books$fiction == TRUE, ]
fiction_books
```

## 9.5 Exercise 3: Exploring iris Dataset

```{r}
# Using the iris dataset
data(iris)

# 1. What are the column names?

# 2. How many observations are there?

# 3. What is the mean Sepal.Length?

# 4. Select only the setosa species

# 5. Find flowers with Petal.Length > 4
```

## 9.6 Exercise 3: Solution

```{r}
# Using the iris dataset
data(iris)

# 1. Column names
colnames(iris)
```

```{r}
# 2. Number of observations
nrow(iris)
```

```{r}
# 3. Mean Sepal.Length
mean(iris$Sepal.Length)
```

```{r}
# 4. Select only setosa species
setosa_only <- iris[iris$Species == "setosa", ]
head(setosa_only)
```

```{r}
# 5. Flowers with Petal.Length > 4
large_petals <- iris[iris$Petal.Length > 4, ]
head(large_petals)
```

# 10 PART 2: Data Import and Manipulation

Now that you understand R’s fundamental data types and structures, we’ll learn how to import data from external files
and manipulate it using both base R and the powerful tidyverse package.

## 10.1 Load Required Packages

```{r}
# Load packages
library(tidyverse)  # Includes dplyr, ggplot2, and more
library(patchwork)  # Combine multiple tidyverse objects
```

# 11 Working with Files and Directories

## 11.1 Understanding Working Directories

```{r}
# Check your current working directory
getwd()

# Set working directory (adjust path as needed)
setwd("~/Desktop/R_bootcamp")  # Mac/Linux
# setwd("C:/Users/YourName/Documents/R_Workshop")  # Windows

# List files in current directory
list.files()

# Better practice: use relative paths or RStudio projects
```

# 12 Load Workshop Datasets: ChickWeight and DNase

For the rest of this workshop, we’ll work with two built-in R datasets that are great for learning data manipulation:

**ChickWeight:** A study tracking chick weights over time under different die

-   `weight`: Body weight of the chick (grams)

-   `Time`: Number of days since birth

-   `Chick`: Unique chick identifier

-   `Diet`: Experimental diet (1, 2, 3, or 4)

This study asks the question: Does diet affect chicken growth rate?

-   Compares chicken growth trajectories across the 4 diet groups.

**DNase:** An enzyme assay measuring optical density at various concentrations

`Run`: Assay run identifier

`conc`: Protein concentration

`density`: Optical density reading

This is data from an ELISA-style assay for DNase I enzyme activity, where the experiment:

-   Prepared wells with known concentrations of DNase 1 protein

-   Ran the assay and measured the optical density (which reflects how much enzymatic reaction occured).

-   Each 'Run" (1-11) is a complete replicate of the entire standard curve experiment.

```{r}
# Load and preview our datasets
data(ChickWeight)
data(DNase)

# Take a first look at ChickWeight
head(ChickWeight)
```

```{r}
str(ChickWeight)
```

```{r}
summary(ChickWeight)
```

```{r}
# Plot overview of ChickWeight growth curves
p1 <- ggplot(ChickWeight, aes(x = Time, y = weight, group = Chick, color = Diet)) +
  geom_line(alpha = 0.5) +
  scale_colour_viridis_d() +
  labs(x = "Days Since Birth", y = "Weight (g)") +
  theme_classic()

# Group diets together
ChickWeight_avg <- ChickWeight %>%
  group_by(Diet, Time) %>%
  summarize(
    mean_weight = mean(weight),
    sd_weight = sd(weight)
  )

# Plot growth curves per diet
p2 <- ggplot(ChickWeight_avg, aes(x = Time, y = mean_weight, color = Diet)) +
  geom_point() +
  geom_line() +
  scale_colour_viridis_d() +
  geom_errorbar(aes(ymin = mean_weight - sd_weight, 
                    ymax = mean_weight + sd_weight), width = 0.5) +
  labs(x = "Days Since Birth", y = "Mean Weight (g)") +
  theme_classic()

p1 + p2
```

```{r}
# Take a first look at DNase
head(DNase)
```

```{r}
str(DNase)
```

```{r}
summary(DNase)
```

```{r}
# Plot overview of DNase I enzyme activity
p3 <- ggplot(DNase, aes(x = conc, y = density, color = Run)) +
  geom_point() +
  geom_line() +
  scale_colour_viridis_d() +
  labs(x = "Known Concentration", y = "Measured Optical Density") +
  theme_classic()

# Combine all replicate runs for standard curve
DNase_avg <- DNase %>%
  group_by(conc) %>%
  summarize(
    mean_density = mean(density),
    sd_density = sd(density)
  )

# Plot standard curve
p4 <- ggplot(DNase_avg, aes(x = conc, y = mean_density)) +
  geom_point(color = "darkblue") +
  geom_line(color = "darkblue") +
  geom_errorbar(aes(ymin = mean_density - sd_density, 
                    ymax = mean_density + sd_density), 
                    width = 0.1, color = "darkblue") +
  labs(x = "Known Concentration", y = "Mean Optical Density") +
  theme_classic()

p3 + p4
```

# 13 Exporting Data

# 13.1 Saving CSV Files

Let’s save our datasets as files to practice import/export:

```{r}
# Save ChickWeight to CSV
write.csv(ChickWeight, "chick_weight.csv", row.names = FALSE)

# Write without quotes around strings
write.csv(ChickWeight, "chick_weight_quotes.csv", 
          row.names = FALSE, quote = FALSE)

# Use readr for better CSV writing
write_csv(ChickWeight, "chick_weight_readr.csv")

# Save DNase to CSV
write.csv(DNase, "dnase_assay.csv", row.names = FALSE)

# Create a messy version of DNase with issues for cleaning practice
messy_DNase <- data.frame(
  DENSITY = c("  0.017  ", "0.018", "0.121", "ERROR", "0.124"),
  conc = c(0.04882812, 0.04882812, 0.19531250, 0.19531250, 0.39062500),
  Run = c("Run 1", "run 1", "RUN 1", NA, "Run_1")
)

# Save messy_DNase to CSV
write.csv(messy_DNase, "messy_DNase.csv", row.names = FALSE)
```

# 14 Importing Data

## 14.1 Reading CSV Files

```{r}
# Basic CSV reading
chicks1 <- read.csv("chick_weight.csv")
head(chicks1)
```

```{r}
# With additional parameters
chicks2 <- read.csv("chick_weight.csv",
                  stringsAsFactors = FALSE,  # Keep strings as characters
                  na.strings = c("NA", "N/A", ""))  # Define NA values
str(chicks2)
```

```{r}
# Using readr (tidyverse) - often better!
chicks3 <- read_csv("chick_weight.csv")  # Note: read_csv not read.csv
glimpse(chicks3)  # tidyverse way to view structure
```

# 15 Managing Different Delimiters

```{r}
# Create tab-delimited file
write.table(ChickWeight, "chick_weight.txt", sep = "\t", row.names = FALSE)

# Read tab-delimited
tab_data <- read.table("chick_weight.txt", header = TRUE, sep = "\t")
head(tab_data)
```

```{r}
# For other delimiters (semicolon, pipe, etc.)
# read.table("file.txt", sep = ";")  # Semicolon
# read.table("file.txt", sep = "|")  # Pipe
```

# 16 Handling Missing Data

Missing data is extremely common in real-world datasets. Learning to identify and handle `NA` values is essential.

```{r}
# Create a version of ChickWeight with some missing values for practice
chicks_with_na <- ChickWeight
chicks_with_na$weight[c(5, 15, 25, 50)] <- NA  # Introduce some NAs
write.csv(chicks_with_na, "chicks_with_na.csv", row.names = FALSE)

# Read and check for missing values
df_with_na <- read.csv("chicks_with_na.csv")
summary(df_with_na)
```

```{r}
# Count NAs per column
colSums(is.na(df_with_na))
```

```{r}
# Find rows with any NA
rows_with_na <- df_with_na[!complete.cases(df_with_na), ]
rows_with_na
```

```{r}
# Remove rows with NA
df_no_na <- na.omit(df_with_na)
nrow(df_no_na)
```

```{r}
# Replace NA with specific value (e.g., mean weight)
df_filled <- df_with_na
df_filled$weight[is.na(df_filled$weight)] <- mean(df_filled$weight, na.rm = TRUE)
head(df_filled, 30)
```

# 17 Base R Data Manipulation

## 17.1 Subsetting and Filtering

```{r}
# Work with ChickWeight
df <- as.data.frame(ChickWeight)

# Select columns
df_subset1 <- df[, c("weight", "Time", "Diet")]
head(df_subset1)
```

```{r}
# Select columns by number
df_subset2 <- df[, c(1, 2, 4)]
head(df_subset2)
```

```{r}
# Filter rows - chicks heavier than 100 grams
heavy_chicks <- df[df$weight > 100, ]
head(heavy_chicks)
```

```{r}
# Complex conditions - Diet 1 chicks heavier than 100g
diet1_heavy <- df[df$Diet == 1 & df$weight > 100, ]
head(diet1_heavy)
```

```{r}
# Using subset() function
subset_result <- subset(df, Time > 10 & Diet %in% c(1, 2))
head(subset_result)
```

## 17.2 Adding and Modifying Columns

```{r}
# Add new column - weight in kilograms
df$weight_kg <- df$weight / 1000
head(df)
```

```{r}
# Conditional new column - weight category
df$weight_category <- ifelse(df$weight >= 150, "Heavy", 
                        ifelse(df$weight >= 100, "Medium", "Light"))
head(df)
```

```{r}
# Modify existing column - create age groups
df$age_group <- cut(df$Time, 
                    breaks = c(-1, 7, 14, 21), 
                    labels = c("Week1", "Week2", "Week3"))
head(df)
```

```{r}
# Remove columns
df_reduced <- df[, !names(df) %in% c("weight_kg", "weight_category")]
head(df_reduced)
```

# 18 Introduction to Tidyverse/dplyr

The tidyverse is a collection of R packages designed for data science. The dplyr package within tidyverse provides a
grammar of data manipulation that makes your code more readable and easier to write.

## 18.1 The Pipe Operator

%\>%

The pipe operator%\>%is one of the most powerful features of tidyverse. It takes the output from one function and passes
it as the first argument to the next function, allowing you to chain operations together.

```{r}
# Traditional nested approach (hard to read)
result1 <- head(sort(ChickWeight$weight), 3)
result1
```

```{r}
# With pipe (read left to right)
result2 <- ChickWeight$weight %>% 
  sort() %>% 
  head(3)
result2
```

```{r}
# Multiple operations
ChickWeight %>% 
  nrow()  # Count rows
```

```{r}
ChickWeight %>% 
  summary()  # Get summary
```

## 18.2 Core dplyr Verbs

The dplyr package has five main “verbs” (functions) that cover most data manipulation needs:

### 18.2.1 select() - Choose Columns

```{r}
# Select specific columns
ChickWeight %>% 
  select(weight, Time, Diet) %>%
  head()
```

```{r}
# Select columns by pattern
ChickWeight %>% 
  select(starts_with("w")) %>%  # Columns starting with 'w'
  head()
```

```{r}
# Select all except certain columns
ChickWeight %>% 
  select(-Chick) %>%
  head()
```

```{r}
# Reorder columns
ChickWeight %>% 
  select(Diet, Chick, Time, everything()) %>%
  head()
```

### 18.2.2 filter() - Choose Rows

```{r}
# Simple filter - chicks heavier than 200g
ChickWeight %>% 
  filter(weight > 200)
```

```{r}
# Multiple conditions (AND)
ChickWeight %>% 
  filter(weight > 200, Diet == 1)
```

```{r}
# OR conditions
ChickWeight %>% 
  filter(Time == 0 | Time == 21)
```

```{r}
# Using %in%
ChickWeight %>% 
  filter(Diet %in% c(1, 2)) %>%
  head()
```

```{r}
# Let's look at DNase - filter for high density readings
DNase %>% 
  filter(density > 1.5)
```

### 18.2.3 mutate() - Create/Modify Columns

```{r}
# Add single column - weight in kg
ChickWeight %>% 
  mutate(weight_kg = weight / 1000) %>%
  head()
```

```{r}
# Add multiple columns
ChickWeight %>% 
  mutate(
    weight_kg = weight / 1000,
    is_heavy = weight > 150,
    time_weeks = Time / 7
  ) %>% 
  head()
```

```{r}
# Modify existing column
ChickWeight %>% 
  mutate(Time = Time + 1) %>%  # Shift time by 1
  head()
```

```{r}
# Use case_when for complex conditions
ChickWeight %>% 
  mutate(
    weight_class = case_when(
      weight >= 200 ~ "Large",
      weight >= 100 ~ "Medium",
      weight >= 50 ~ "Small",
      TRUE ~ "Very Small"  # Default case
    )
  ) %>%
  head()
```

### 18.2.4 arrange() - Sort Data

```{r}
# Sort by one column
ChickWeight %>% 
  arrange(weight) %>%
  head()
```

```{r}
# Sort descending
ChickWeight %>% 
  arrange(desc(weight)) %>%
  head()
```

```{r}
# Sort by multiple columns
ChickWeight %>% 
  arrange(Diet, desc(weight)) %>%
  head()
```

### 18.2.5 summarize() - Compute Summaries

```{r}
# Single summary
ChickWeight %>% 
  summarize(mean_weight = mean(weight))
```

```{r}
# Multiple summaries
ChickWeight %>% 
  summarize(
    mean_weight = mean(weight),
    max_weight = max(weight),
    n_observations = n(),
    n_chicks = n_distinct(Chick)
  )
```

```{r}
# With filter first
ChickWeight %>% 
  filter(Diet == 1) %>% 
  summarize(
    mean_weight = mean(weight),
    sd_weight = sd(weight)
  )
```

```{r}
# Now with DNase
DNase %>% 
  summarize(
    mean_density = mean(density),
    max_density = max(density),
    n_runs = n_distinct(Run)
  )
```

## 18.3 group_by() - Grouped Operations

The group_by() function is incredibly powerful when combined with summarize() or mutate(). It allows you to perform
operations within groups of your data.

```{r}
# Group and summarize - mean weight by Diet
ChickWeight %>% 
  group_by(Diet) %>% 
  summarize(
    count = n(),
    mean_weight = mean(weight),
    sd_weight = sd(weight)
  )
```

```{r}
# Group and mutate - add diet average to each row
ChickWeight %>% 
  group_by(Diet) %>% 
  mutate(
    diet_mean_weight = mean(weight),
    weight_diff = weight - diet_mean_weight
  ) %>% 
  select(weight, Diet, diet_mean_weight, weight_diff) %>% 
  head(10)
```

```{r}
# Multiple grouping variables - by Diet and Time
ChickWeight %>% 
  group_by(Diet, Time) %>% 
  summarize(
    count = n(),
    mean_weight = mean(weight)
  )
```

```{r}
# DNase example - summarize by Run
DNase %>% 
  group_by(Run) %>% 
  summarize(
    n_measurements = n(),
    mean_density = mean(density),
    max_density = max(density)
  )
```

# 19 Combining Multiple Operations

One of the greatest strengths of dplyr is the ability to chain multiple operations together into a single, readable
pipeline.

```{r}
# Complex data pipeline with ChickWeight
result <- ChickWeight %>% 
  filter(Time >= 10) %>%                              # Filter for later timepoints
  mutate(weight_class = case_when(                    # Add weight category
    weight >= 200 ~ "Heavy",
    weight >= 100 ~ "Medium",
    TRUE ~ "Light"
  )) %>% 
  group_by(Diet, weight_class) %>%                    # Group
  summarize(
    count = n(),
    mean_weight = round(mean(weight), 1)
  ) %>% 
  arrange(Diet, desc(count))                          # Sort

result
```

```{r}
# Another example: Heaviest chick in each diet group
top_chicks <- ChickWeight %>% 
  group_by(Diet) %>% 
  slice_max(weight, n = 1) %>%  # Get heaviest per group
  select(Diet, Chick, weight, Time) %>% 
  arrange(desc(weight))

top_chicks
```

```{r}
# DNase pipeline - find the run with highest average density
DNase %>% 
  group_by(Run) %>% 
  summarize(
    mean_density = mean(density),
    max_conc = max(conc)
  ) %>% 
  arrange(desc(mean_density)) %>% 
  head(5)
```

# 20 Data Cleaning Example

Real-world data is often messy. Here’s a practical example of cleaning a problematic dataset:

```{r}
# Read the messy data
messy <- read.csv("messy_DNase.csv", stringsAsFactors = FALSE)
print("Original messy data:")
```

```{r}
messy
```

```{r}
# Clean it up
clean <- messy %>% 
  # Clean column names
  rename_all(tolower) %>%                         # Lowercase column names
  mutate(
    density = str_trim(density),                  # Remove whitespace
    density = as.numeric(density),                # Convert to numeric (ERROR becomes NA)
    run = str_trim(run),                          # Remove whitespace
    run = str_to_lower(run),                      # Lowercase
    run = str_replace_all(run, "_", " "),         # Replace underscores
    run = str_to_title(run)                       # Proper case
  ) %>% 
  filter(!is.na(density)) %>%                     # Remove rows with no density
  filter(!is.na(run))                             # Remove rows with no run

print("Cleaned data:")
```

```{r}
clean
```

# 21 Practice Exercises: Part 2

## 21.1 Exercise 1: Data Import and Basic Manipulation

```{r}
# Using ChickWeight data:

# 1. Save ChickWeight as a CSV file called "my_chicks.csv"

# 2. Read it back in

# 3. Filter for chicks on Diet 3 only

# 4. Calculate the average weight by Time point for Diet 3
```

## 21.2 Exercise 1: Solution

```{r}
# 1. Save as CSV
write.csv(ChickWeight, "my_chicks.csv", row.names = FALSE)

# 2. Read it back
chicks_read <- read.csv("my_chicks.csv")

# 3. Filter for Diet 3 chicks
diet3_chicks <- chicks_read %>% 
  filter(Diet == 3)
head(diet3_chicks)
```

```{r}
# 4. Average weight by Time for Diet 3
chicks_read %>% 
  filter(Diet == 3) %>% 
  group_by(Time) %>% 
  summarize(avg_weight = mean(weight))
```

## 21.3 Exercise 2: Complex dplyr Pipeline

```{r}
# Using the ChickWeight data:
# 1. Filter for observations at Time >= 10
# 2. Add a column for weight_range: "Light" (<100), "Medium" (100-200), "Heavy" (>200)
# 3. Count chicks in each weight_range by Diet
# 4. Arrange by Diet and count (descending)
```

## 21.4 Exercise 2: Solution

```{r}
result <- ChickWeight %>% 
  filter(Time >= 10) %>% 
  mutate(
    weight_range = case_when(
      weight < 100 ~ "Light",
      weight <= 200 ~ "Medium",
      TRUE ~ "Heavy"
    )
  ) %>% 
  group_by(Diet, weight_range) %>% 
  summarize(count = n()) %>% 
  arrange(Diet, desc(count))

result
```

## 21.5 Exercise 3: Data Cleaning Challenge

```{r}
# Create messy ChickWeight data
messy_chicks <- data.frame(
  Weight = c("  42  ", "51", "59", "ERROR", "64"),
  time = c(0, 2, 4, 6, 8),
  CHICK = c("1", "1", "1", "1", "1"),
  diet = c("Diet 1", "diet 1", "DIET 1", NA, "Diet_1")
)

# Clean this data:
# 1. Fix column name formatting (lowercase)
# 2. Clean Weight values (trim whitespace, convert to numeric - ERROR becomes NA)
# 3. Standardize Diet values (trim, replace underscores, proper case)
# 4. Remove rows with missing weight
# 5. Remove rows with missing diet
```

## 21.6 Exercise 3: Solution

```{r}
# Utilize messy ChickWeight data
messy_chicks <- data.frame(
  Weight = c("  42  ", "51", "59", "ERROR", "64"),
  time = c(0, 2, 4, 6, 8),
  CHICK = c("1", "1", "1", "1", "1"),
  diet = c("Diet 1", "diet 1", "DIET 1", NA, "Diet_1")
)

# Clean the ChickWeight data
clean_chicks <- messy_chicks %>% 
  # Clean column names
  rename_all(tolower) %>%                         # Lowercase column names
  mutate(
    weight = str_trim(weight),                    # Remove whitespace
    weight = as.numeric(weight),                  # Convert to numeric (ERROR becomes NA)
    diet = str_trim(diet),                        # Remove whitespace
    diet = str_to_lower(diet),                    # Lowercase
    diet = str_replace_all(diet, "_", " "),       # Replace underscores
    diet = str_to_title(diet)                     # Proper case
  ) %>% 
  filter(!is.na(weight)) %>%                      # Remove rows with no weight
  filter(!is.na(diet))                            # Remove rows with no diet

print("Original messy data:")
```

```{r}
messy_chicks
```

```{r}
print("Cleaned data:")
```

```{r}
clean_chicks
```

# 22 Joining Data (Bonus Content)

When working with real data, you often need to combine information from multiple tables. Joins are essential for this
task.

```{r}
# Create related datasets based on our chick data
# Minimalist tidy join example
x <- tibble(id = c(1, 2, 3), x_val = c("a", "b", "c"))
y <- tibble(id = c(2, 3, 4), y_val = c("B", "C", "D"))

left_join(x, y, by = "id")
```

```{r}
inner_join(x, y, by = "id")
```

```{r}
full_join(x, y, by = "id")
```

```{r}
# More detalied join examples from our main dataset
# ChickWeight has factor columns, so we convert to numeric for easier joining
# Get summary of max weight per chick
chick_summary <- ChickWeight %>% 
  mutate(
    Chick = as.numeric(as.character(Chick)),
    Diet = as.numeric(as.character(Diet))
  ) %>% 
  group_by(Chick, Diet) %>% 
  summarize(max_weight = max(weight)) %>% 
  head(10)

# Create diet information table (numeric Diet to match our converted data)
diet_info <- data.frame(
  Diet = c(1, 2, 3),
  diet_name = c("Standard", "High Protein", "Low Fat"),
  cost_per_day = c(1.00, 1.50, 1.25)
)

# Create chick origin table (numeric Chick to match our converted data)
chick_origin <- data.frame(
  Chick = c(1, 2, 3, 18, 20),
  farm = c("Farm A", "Farm A", "Farm B", "Farm B", "Farm C")
)

# Different types of joins
# Left join - all from left, matching from right
left_result <- chick_summary %>% 
  left_join(chick_origin, by = "Chick")
print("Left Join (with origin):")
```

```{r}
left_result
```

```{r}
# Inner join - only matching records
inner_result <- chick_summary %>% 
  inner_join(diet_info, by = "Diet")
print("Inner Join (with diet info):")
```

```{r}
inner_result
```

```{r}
# Full join - all records from both tables
full_result <- chick_summary %>% 
  full_join(chick_origin, by = "Chick")
print("Full Join (with origin):")
```

```{r}
full_result
```

```{r}
# Multiple joins
complete_data <- chick_summary %>% 
  left_join(diet_info, by = "Diet") %>% 
  left_join(chick_origin, by = "Chick")
print("Complete Data:")
```

```{r}
complete_data
```

# 23 Row Names from Columns (Bonus Content)

```{r}
# Create a summary dataframe with meaningful names
chick_max <- ChickWeight %>% 
  group_by(Chick) %>% 
  summarize(max_weight = max(weight), final_time = max(Time)) %>% 
  head(5) %>% 
  as.data.frame()

# Move a data frame column to rownames
df_rownames <- column_to_rownames(chick_max, var = "Chick")
df_rownames
```

```{r}
# Make a data frame column from the rownames
df_column <- rownames_to_column(df_rownames, "Chick")
df_column
```

# 24 Tips and Best Practices

## 24.1 Common Pitfalls to Avoid

1.  **Forgetting na.rm = TRUE**: Always use when calculating statistics on data with missing values

2.  **Not checking data types**: Use `str()` or `glimpse()` frequently

3.  **Overwriting original data**: Keep a copy of raw data

4.  **Not handling factors properly**: Use `stringsAsFactors = FALSE` or convert as needed

5.  **Forgetting to load packages**: Always load tidyverse at the start

# 25 Practice Assignment

To solidify your learning, complete the following exercises on your own:

1.  **Practice with vectors**: Create vectors representing:

    -   Daily weights of a chick for a week

    -   Names of different diets

    -   Whether each measurement passed quality control (TRUE/FALSE)

2.  **Explore a built-in dataset**: Choose ChickWeight or DNase and:

    -   Find its dimensions

    -   Identify column types

    -   Calculate summary statistics

    -   Extract interesting subsets

3.  **Create a personal data frame**: Make a data frame about something relevant to you (experiments, samples,
    measurements, etc.) with at least 4 columns and 6 rows

4.  **Challenge**: Write code to find all chicks in `ChickWeight` that have both weight \> 200 AND Time \> 10

5.  **Practice Data Import/Export**:

    -   Save a subset of ChickWeight as a CSV

    -   Import it, explore it, export a cleaned version

6.  **Master the Core dplyr Verbs**:

    -   Practice each verb (select, filter, mutate, arrange, summarize) at least 5 times on ChickWeight

    -   Try combining them in different orders

7.  **Data Cleaning Challenge**:

    -   Create your own messy dataset with at least 5 types of issues

    -   Write code to clean all issues

8.  **Group Operations**:

    -   Using ChickWeight, calculate mean weight by Diet and Time

    -   Find the heaviest chick in each Diet category

9.  **Pipeline Practice**:

    -   Write a pipeline with at least 6 operations chained together using ChickWeight

    -   Comment each step explaining what it does

# 26 Additional Resources

-   [RStudio Cheat Sheets](https://www.rstudio.com/resources/cheatsheets/)

-   [R for Data Science (free online book)](https://r4ds.had.co.nz/)

-   [swirl: Learn R in R](https://swirlstats.com/)

-   [dplyr Cheat Sheet](https://github.com/rstudio/cheatsheets/blob/main/data-transformation.pdf)

-   [R for Data Science - Data Transformation](https://r4ds.had.co.nz/transform.html)

-   [Tidyverse Documentation](https://www.tidyverse.org/)

-   [Data Import Cheat Sheet](https://github.com/rstudio/cheatsheets/blob/main/data-import.pdf)

# 27 Workshop Complete!

Congratulations on completing this introductory R Programming Workshop! You’ve learned:

-   **R Fundamentals**: Data types, variables, vectors, and data structures

-   **Working with Data Frames**: Creating, manipulating, and exploring tabular data

-   **Data Import/Export**: Reading and writing CSV, Excel, and other file formats

-   **Data Manipulation**: Both base R and tidyverse/dplyr approaches

-   **Data Cleaning**: Handling missing values and messy data

-   **Best Practices**: Tips for writing clean, efficient R code

You’ve practiced these skills using real biological datasets (ChickWeight and DNase) that will prepare you for more
advanced analyses in future workshops!

# 28 Session Info

For reproducibility, here’s the R environment used:

```{r}
sessionInfo()
```
